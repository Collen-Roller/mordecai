{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just a playground for extracting geolocations from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Scroll ID\n",
    "import sys\n",
    "import csv\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch()\n",
    "\n",
    "count = 10000\n",
    "geo_file = \"geonames.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = {\n",
    "    'size' : count,\n",
    "    \"_source\": [\"asciiname\", \"coordinates\"],\n",
    "    \"query\":{\n",
    "        \"type\" : {\n",
    "            \"value\" : \"geoname\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(geo_file, mode='w') as csv_file:\n",
    "    fieldnames = ['id','coordinates','asciiname']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    response = es.search(index=\"geonames\", doc_type='geoname', body=doc ,scroll='1m')\n",
    "    scroll = response['_scroll_id']\n",
    "    print(\"Scroll ID %s\" % scroll)\n",
    "\n",
    "#     orig_stdout = sys.stdout\n",
    "#     f = open(geo_file, 'w')\n",
    "#     sys.stdout = f\n",
    "#     print(\"id,coordinates,asciiname\") # print header\n",
    "\n",
    "    #print first 10000\n",
    "    for hit in response['hits']['hits']:\n",
    "#         print(\"%s,\\\"%s\\\",\\\"%s\\\"\" % (hit['_id'],hit['_source']['coordinates'],hit['_source']['asciiname']))\n",
    "        writer.writerow({'id':hit['_id'], 'coordinates':hit['_source']['coordinates'], 'asciiname':hit['_source']['asciiname']})\n",
    "\n",
    "    #Now use the scroll is to get the rest of the records\n",
    "    while count < 11741135:  \n",
    "        response = es.scroll(scroll_id = scroll, scroll = '1m')\n",
    "        for hit in response['hits']['hits']:\n",
    "#             print(\"%s,\\\"%s\\\",\\\"%s\\\"\" % (hit['_id'],hit['_source']['coordinates'],hit['_source']['asciiname']))\n",
    "            writer.writerow({'id':hit['_id'], 'coordinates':hit['_source']['coordinates'], 'asciiname':hit['_source']['asciiname']})\n",
    "\n",
    "        count += 10000\n",
    "\n",
    "#     sys.stdout = orig_stdout\n",
    "#     f.close()  \n",
    "\n",
    "    # Done outputting records!\n",
    "    print(\"Done\")\n",
    "\n",
    "#500M Large!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11741135, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(geo_file)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/opt/python/bin/python3.6'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys; sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'word': 'Oxford',\n",
       "  'spans': [{'start': 16, 'end': 22}],\n",
       "  'country_predicted': 'GBR',\n",
       "  'country_conf': 0.96474487,\n",
       "  'geo': {'admin1': 'England',\n",
       "   'lat': '51.75222',\n",
       "   'lon': '-1.25596',\n",
       "   'country_code3': 'GBR',\n",
       "   'geonameid': '2640729',\n",
       "   'place_name': 'Oxford',\n",
       "   'feature_class': 'P',\n",
       "   'feature_code': 'PPLA2'}},\n",
       " {'word': 'Ottawa',\n",
       "  'spans': [{'start': 26, 'end': 32}],\n",
       "  'country_predicted': 'CAN',\n",
       "  'country_conf': 0.83302397,\n",
       "  'geo': {'admin1': 'Ontario',\n",
       "   'lat': '45.41117',\n",
       "   'lon': '-75.69812',\n",
       "   'country_code3': 'CAN',\n",
       "   'geonameid': '6094817',\n",
       "   'place_name': 'Ottawa',\n",
       "   'feature_class': 'P',\n",
       "   'feature_code': 'PPLC'}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mordecai import Geoparser\n",
    "geo = Geoparser()\n",
    "geo.geoparse(\"I traveled from Oxford to Ottawa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 records\n",
      "Completed 10000 records\n",
      "Completed 20000 records\n",
      "Completed 30000 records\n",
      "Completed 40000 records\n",
      "Completed 50000 records\n",
      "Completed 60000 records\n",
      "Completed 70000 records\n",
      "Completed 80000 records\n",
      "Completed 90000 records\n",
      "Completed 100000 records\n",
      "Completed 110000 records\n",
      "Completed 120000 records\n",
      "Completed 130000 records\n",
      "Completed 140000 records\n",
      "Completed 150000 records\n",
      "Completed 160000 records\n",
      "Completed 170000 records\n",
      "Completed 180000 records\n",
      "Completed 190000 records\n",
      "Completed 200000 records\n",
      "Completed 210000 records\n",
      "Completed 220000 records\n",
      "Completed 230000 records\n",
      "Completed 240000 records\n",
      "Completed 250000 records\n",
      "Completed 260000 records\n",
      "Completed 270000 records\n",
      "Completed 280000 records\n",
      "Completed 290000 records\n",
      "Completed 300000 records\n",
      "Completed 310000 records\n",
      "Completed 320000 records\n",
      "Completed 330000 records\n",
      "Completed 340000 records\n",
      "Completed 350000 records\n",
      "Completed 360000 records\n",
      "Completed 370000 records\n",
      "Completed 380000 records\n",
      "Completed 390000 records\n",
      "Completed 400000 records\n",
      "Completed 410000 records\n",
      "Completed 420000 records\n",
      "Completed 430000 records\n",
      "Completed 440000 records\n",
      "Completed 450000 records\n",
      "Completed 460000 records\n",
      "Completed 470000 records\n",
      "Completed 480000 records\n",
      "Completed 490000 records\n",
      "Completed 500000 records\n",
      "Completed 510000 records\n",
      "Completed 520000 records\n",
      "Completed 530000 records\n",
      "Completed 540000 records\n",
      "Completed 550000 records\n",
      "Completed 560000 records\n",
      "Completed 570000 records\n",
      "Completed 580000 records\n",
      "Completed 590000 records\n",
      "Completed 600000 records\n",
      "Completed 610000 records\n",
      "Completed 620000 records\n",
      "Completed 630000 records\n",
      "Completed 640000 records\n",
      "Completed 650000 records\n",
      "Completed 660000 records\n",
      "Completed 670000 records\n",
      "Completed 680000 records\n",
      "Completed 690000 records\n",
      "Completed 700000 records\n",
      "Completed 710000 records\n",
      "Completed 720000 records\n",
      "Completed 730000 records\n",
      "Completed 740000 records\n",
      "Completed 750000 records\n",
      "Completed 760000 records\n",
      "Completed 770000 records\n",
      "Completed 780000 records\n",
      "Completed 790000 records\n",
      "Completed 800000 records\n",
      "Completed 810000 records\n",
      "Completed 820000 records\n",
      "Completed 830000 records\n",
      "Completed 840000 records\n",
      "Completed 850000 records\n",
      "Completed 860000 records\n",
      "Completed 870000 records\n",
      "Completed 880000 records\n",
      "Completed 890000 records\n",
      "Completed 900000 records\n",
      "Completed 910000 records\n",
      "Completed 920000 records\n",
      "Completed 930000 records\n",
      "Completed 940000 records\n",
      "Completed 950000 records\n",
      "Completed 960000 records\n",
      "Completed 970000 records\n",
      "Completed 980000 records\n",
      "Completed 990000 records\n",
      "Completed 1000000 records\n",
      "Completed 1010000 records\n",
      "Completed 1020000 records\n",
      "Completed 1030000 records\n",
      "Completed 1040000 records\n",
      "Completed 1050000 records\n",
      "Completed 1060000 records\n",
      "Completed 1070000 records\n",
      "Completed 1080000 records\n",
      "Completed 1090000 records\n",
      "Completed 1100000 records\n",
      "Completed 1110000 records\n",
      "Completed 1120000 records\n",
      "Completed 1130000 records\n",
      "Completed 1140000 records\n",
      "Completed 1150000 records\n",
      "Completed 1160000 records\n",
      "Completed 1170000 records\n",
      "Completed 1180000 records\n",
      "Completed 1190000 records\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/AFRL/MEADE/mordecai/mordecai/geoparse.py\u001b[0m in \u001b[0;36mgeoparse\u001b[0;34m(self, doc, verbose)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ents\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m         \u001b[0mproced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_country\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproced\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AFRL/MEADE/mordecai/mordecai/geoparse.py\u001b[0m in \u001b[0;36minfer_country\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ents\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m         \u001b[0mproced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_country_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_maj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproced\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AFRL/MEADE/mordecai/mordecai/geoparse.py\u001b[0m in \u001b[0;36mmake_country_features\u001b[0;34m(self, doc, require_maj)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0ment_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_lookup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0ment_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Evaluate\n",
    "missed = []\n",
    "achieved = []\n",
    "\n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    #lets parse each locations!\n",
    "    #print(row['asciiname'])\n",
    "    res = geo.geoparse(row['asciiname'])\n",
    "    if res:\n",
    "        achieved.append(row['asciiname'])\n",
    "    else:\n",
    "        missed.append(row['asciiname'])\n",
    "    \n",
    "    if count % 10000 == 0:\n",
    "        print(\"Completed %s records\" % count)\n",
    "    count += 1\n",
    "    \n",
    "print(\"Finally Done!\")\n",
    "print(\"%s/11741135 achieved\" % len(achieved))\n",
    "print(\"%s/11741135 missed\" % len(missed))\n",
    "#11,741,135 -> This will take a long time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130501/11741135 achieved\n",
      "1065910/11741135 missed\n"
     ]
    }
   ],
   "source": [
    "print(\"%s/11741135 achieved\" % len(achieved))\n",
    "print(\"%s/11741135 missed\" % len(missed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file open\n",
      "Completed 1000 records\n",
      "Completed 2000 records\n",
      "Completed 3000 records\n",
      "Completed 4000 records\n",
      "Completed 5000 records\n",
      "Completed 6000 records\n",
      "Completed 7000 records\n",
      "Completed 8000 records\n",
      "Completed 9000 records\n",
      "Completed 10000 records\n",
      "Completed 11000 records\n",
      "Completed 12000 records\n",
      "Completed 13000 records\n",
      "Completed 14000 records\n",
      "Completed 15000 records\n",
      "Completed 16000 records\n",
      "Completed 17000 records\n",
      "Completed 18000 records\n",
      "Completed 19000 records\n",
      "Completed 20000 records\n",
      "Completed 21000 records\n",
      "Completed 22000 records\n",
      "Completed 23000 records\n",
      "Completed 24000 records\n",
      "Completed 25000 records\n",
      "Completed 26000 records\n",
      "Completed 27000 records\n",
      "Completed 28000 records\n",
      "Completed 29000 records\n",
      "Completed 30000 records\n",
      "Completed 31000 records\n",
      "Completed 32000 records\n",
      "Completed 33000 records\n",
      "Completed 34000 records\n",
      "Completed 35000 records\n",
      "Completed 36000 records\n",
      "Completed 37000 records\n",
      "Completed 38000 records\n",
      "Completed 39000 records\n",
      "Completed 40000 records\n",
      "Completed 41000 records\n",
      "Completed 42000 records\n",
      "Completed 43000 records\n",
      "Completed 44000 records\n",
      "Completed 45000 records\n",
      "Completed 46000 records\n",
      "Completed 47000 records\n",
      "Completed 48000 records\n",
      "Completed 49000 records\n",
      "Completed 50000 records\n",
      "Completed 51000 records\n",
      "Completed 52000 records\n",
      "Finally Done!\n",
      "34156/52709 achieved\n",
      "18553/52709 missed\n",
      "CPU times: user 4h 26min 36s, sys: 44min 37s, total: 5h 11min 13s\n",
      "Wall time: 2h 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Try World Locations (Context + Uppercase)\n",
    "\n",
    "q = [\"Where is \"]\n",
    "\n",
    "wl_got = []\n",
    "wl_missed = []\n",
    "\n",
    "c = 0\n",
    "with open(\"../Rasa/roger_nlu/location_data/world_locations_ed2.txt\", 'r') as wlf:\n",
    "    print(\"file open\")\n",
    "    line = wlf.readline()\n",
    "    while line:\n",
    "        res = geo.geoparse(\"%s%s\" % (q,line.strip()))\n",
    "        if res:\n",
    "            wl_got.append(line.strip())\n",
    "        else:\n",
    "            wl_missed.append(line.strip())\n",
    "        line = wlf.readline()\n",
    "        c += 1\n",
    "        \n",
    "        if c % 1000 == 0:\n",
    "            print(\"Completed %s records\" % c)\n",
    "\n",
    "# Done!\n",
    "print(\"Finally Done!\")\n",
    "print(\"%s/%s achieved\" % (len(wl_got), c))\n",
    "print(\"%s/%s missed\" % (len(wl_missed), c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file open\n",
      "Completed 1000 records\n",
      "Completed 2000 records\n",
      "Completed 3000 records\n",
      "Completed 4000 records\n",
      "Completed 5000 records\n",
      "Completed 6000 records\n",
      "Completed 7000 records\n",
      "Completed 8000 records\n",
      "Completed 9000 records\n",
      "Completed 10000 records\n",
      "Completed 11000 records\n",
      "Completed 12000 records\n",
      "Completed 13000 records\n",
      "Completed 14000 records\n",
      "Completed 15000 records\n",
      "Completed 16000 records\n",
      "Completed 17000 records\n",
      "Completed 18000 records\n",
      "Completed 19000 records\n",
      "Completed 20000 records\n",
      "Completed 21000 records\n",
      "Completed 22000 records\n",
      "Completed 23000 records\n",
      "Completed 24000 records\n",
      "Completed 25000 records\n",
      "Completed 26000 records\n",
      "Completed 27000 records\n",
      "Completed 28000 records\n",
      "Completed 29000 records\n",
      "Completed 30000 records\n",
      "Completed 31000 records\n",
      "Completed 32000 records\n",
      "Completed 33000 records\n",
      "Completed 34000 records\n",
      "Completed 35000 records\n",
      "Completed 36000 records\n",
      "Completed 37000 records\n",
      "Completed 38000 records\n",
      "Completed 39000 records\n",
      "Completed 40000 records\n",
      "Completed 41000 records\n",
      "Completed 42000 records\n",
      "Completed 43000 records\n",
      "Completed 44000 records\n",
      "Completed 45000 records\n",
      "Completed 46000 records\n",
      "Completed 47000 records\n",
      "Completed 48000 records\n",
      "Completed 49000 records\n",
      "Completed 50000 records\n",
      "Completed 51000 records\n",
      "Completed 52000 records\n",
      "Finally Done!\n",
      "5296/52709 achieved\n",
      "47413/52709 missed\n",
      "CPU times: user 48min 49s, sys: 7min 13s, total: 56min 2s\n",
      "Wall time: 21min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Try World Locations (Context + lowercase)\n",
    "\n",
    "q = [\"Where is \"]\n",
    "\n",
    "wl_got = []\n",
    "wl_missed = []\n",
    "\n",
    "c = 0\n",
    "with open(\"../Rasa/roger_nlu/location_data/world_locations.txt\", 'r') as wlf:\n",
    "    print(\"file open\")\n",
    "    line = wlf.readline()\n",
    "    while line:\n",
    "        res = geo.geoparse(\"%s%s\" % (q,line.strip()))\n",
    "        if res:\n",
    "            wl_got.append(line.strip())\n",
    "        else:\n",
    "            wl_missed.append(line.strip())\n",
    "        line = wlf.readline()\n",
    "        c += 1\n",
    "        \n",
    "        if c % 1000 == 0:\n",
    "            print(\"Completed %s records\" % c)\n",
    "\n",
    "# Done!\n",
    "print(\"Finally Done!\")\n",
    "print(\"%s/%s achieved\" % (len(wl_got), c))\n",
    "print(\"%s/%s missed\" % (len(wl_missed), c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file open\n",
      "Completed 1000 records\n",
      "Completed 2000 records\n",
      "Completed 3000 records\n",
      "Completed 4000 records\n",
      "Completed 5000 records\n",
      "Completed 6000 records\n",
      "Completed 7000 records\n",
      "Completed 8000 records\n",
      "Completed 9000 records\n",
      "Completed 10000 records\n",
      "Completed 11000 records\n",
      "Completed 12000 records\n",
      "Completed 13000 records\n",
      "Completed 14000 records\n",
      "Completed 15000 records\n",
      "Completed 16000 records\n",
      "Completed 17000 records\n",
      "Completed 18000 records\n",
      "Completed 19000 records\n",
      "Completed 20000 records\n",
      "Completed 21000 records\n",
      "Completed 22000 records\n",
      "Completed 23000 records\n",
      "Completed 24000 records\n",
      "Completed 25000 records\n",
      "Completed 26000 records\n",
      "Completed 27000 records\n",
      "Completed 28000 records\n",
      "Completed 29000 records\n",
      "Completed 30000 records\n",
      "Completed 31000 records\n",
      "Completed 32000 records\n",
      "Completed 33000 records\n",
      "Completed 34000 records\n",
      "Completed 35000 records\n",
      "Completed 36000 records\n",
      "Completed 37000 records\n",
      "Completed 38000 records\n",
      "Completed 39000 records\n",
      "Completed 40000 records\n",
      "Completed 41000 records\n",
      "Completed 42000 records\n",
      "Completed 43000 records\n",
      "Completed 44000 records\n",
      "Completed 45000 records\n",
      "Completed 46000 records\n",
      "Completed 47000 records\n",
      "Completed 48000 records\n",
      "Completed 49000 records\n",
      "Completed 50000 records\n",
      "Completed 51000 records\n",
      "Completed 52000 records\n",
      "Finally Done!\n",
      "6886/52709 achieved\n",
      "45823/52709 missed\n",
      "CPU times: user 1h 10s, sys: 9min 3s, total: 1h 9min 13s\n",
      "Wall time: 27min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Try World Locations (lowercase)\n",
    "\n",
    "wl_got = []\n",
    "wl_missed = []\n",
    "\n",
    "c = 0\n",
    "with open(\"../Rasa/roger_nlu/location_data/world_locations.txt\", 'r') as wlf:\n",
    "    print(\"file open\")\n",
    "    line = wlf.readline()\n",
    "    while line:\n",
    "        res = geo.geoparse(\"%s\" % (line.strip()))\n",
    "        if res:\n",
    "            wl_got.append(line.strip())\n",
    "        else:\n",
    "            wl_missed.append(line.strip())\n",
    "        line = wlf.readline()\n",
    "        c += 1\n",
    "        \n",
    "        if c % 1000 == 0:\n",
    "            print(\"Completed %s records\" % c)\n",
    "\n",
    "# Done!\n",
    "print(\"Finally Done!\")\n",
    "print(\"%s/%s achieved\" % (len(wl_got), c))\n",
    "print(\"%s/%s missed\" % (len(wl_missed), c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file open\n",
      "Completed 1000 records\n",
      "Completed 2000 records\n",
      "Completed 3000 records\n",
      "Completed 4000 records\n",
      "Completed 5000 records\n",
      "Completed 6000 records\n",
      "Completed 7000 records\n",
      "Completed 8000 records\n",
      "Completed 9000 records\n",
      "Completed 10000 records\n",
      "Completed 11000 records\n",
      "Completed 12000 records\n",
      "Completed 13000 records\n",
      "Completed 14000 records\n",
      "Completed 15000 records\n",
      "Completed 16000 records\n",
      "Completed 17000 records\n",
      "Completed 18000 records\n",
      "Completed 19000 records\n",
      "Completed 20000 records\n",
      "Completed 21000 records\n",
      "Completed 22000 records\n",
      "Completed 23000 records\n",
      "Completed 24000 records\n",
      "Completed 25000 records\n",
      "Completed 26000 records\n",
      "Completed 27000 records\n",
      "Completed 28000 records\n",
      "Completed 29000 records\n",
      "Completed 30000 records\n",
      "Completed 31000 records\n",
      "Completed 32000 records\n",
      "Completed 33000 records\n",
      "Completed 34000 records\n",
      "Completed 35000 records\n",
      "Completed 36000 records\n",
      "Completed 37000 records\n",
      "Completed 38000 records\n",
      "Completed 39000 records\n",
      "Completed 40000 records\n",
      "Completed 41000 records\n",
      "Completed 42000 records\n",
      "Completed 43000 records\n",
      "Completed 44000 records\n",
      "Completed 45000 records\n",
      "Completed 46000 records\n",
      "Completed 47000 records\n",
      "Completed 48000 records\n",
      "Completed 49000 records\n",
      "Completed 50000 records\n",
      "Completed 51000 records\n",
      "Completed 52000 records\n",
      "Finally Done!\n",
      "35166/52709 achieved\n",
      "17543/52709 missed\n",
      "CPU times: user 4h 35min, sys: 44min 40s, total: 5h 19min 40s\n",
      "Wall time: 2h 10min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Try World Locations (uppercase)\n",
    "\n",
    "wl_got = []\n",
    "wl_missed = []\n",
    "\n",
    "c = 0\n",
    "with open(\"../Rasa/roger_nlu/location_data/world_locations_ed2.txt\", 'r') as wlf:\n",
    "    print(\"file open\")\n",
    "    line = wlf.readline()\n",
    "    while line:\n",
    "        res = geo.geoparse(\"%s\" % (line.strip()))\n",
    "        if res:\n",
    "            wl_got.append(line.strip())\n",
    "        else:\n",
    "            wl_missed.append(line.strip())\n",
    "        line = wlf.readline()\n",
    "        c += 1\n",
    "        \n",
    "        if c % 1000 == 0:\n",
    "            print(\"Completed %s records\" % c)\n",
    "\n",
    "# Done!\n",
    "print(\"Finally Done!\")\n",
    "print(\"%s/%s achieved\" % (len(wl_got), c))\n",
    "print(\"%s/%s missed\" % (len(wl_missed), c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally Done!\n",
      "2593/3064 achieved\n",
      "471/3064 missed\n"
     ]
    }
   ],
   "source": [
    "print(\"Finally Done!\")\n",
    "print(\"%s/%s achieved\" % (len(wl_got), c))\n",
    "print(\"%s/%s missed\" % (len(wl_missed), c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_locations(filename, loc_type):\n",
    "    list1 = []\n",
    "    with open(filename,'r') as f:\n",
    "        data = json.load(f)\n",
    "    temp = data[loc_type]\n",
    "    for item in temp:\n",
    "        location = item['name']\n",
    "        list1.append(location)\n",
    "    return list1\n",
    "countries = read_locations('../Rasa/roger_nlu/location_data/countries.json',\"countries\")\n",
    "states = read_locations('../Rasa/roger_nlu/location_data/states.json',\"states\")\n",
    "cities = read_locations('../Rasa/roger_nlu/location_data/cities.json', \"cities\")\n",
    "\n",
    "all_locs = countries + states + cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
